{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "290c36cd",
   "metadata": {},
   "source": [
    "# Analyzing the avGFP landscape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05565630",
   "metadata": {},
   "source": [
    "This example walks through the generation of analysis figures for the avGFP brightness landscape, similar to how they were generate ``Interpretable modeling of genotype-phenotype landscapes with state-of-the-art predictive power''."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e005db5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910aee5f",
   "metadata": {},
   "source": [
    "## Prepare the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c670139",
   "metadata": {},
   "source": [
    "First we load the dataset and pre-trained model file. The dataset for avGFP can be generated from the manuscript pipeline found at [https://github.com/usnistgov/lantern/tree/master/manuscript](github.com/usnistgov/lantern/tree/master/manuscript). The pre-trained model parameters are also provided there.\n",
    "\n",
    "First, we load the csv dataset and prepare it as a `LANTERN` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a592e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from lantern.dataset import Dataset\n",
    "\n",
    "df = pd.read_csv(\"../manuscript/data/processed/gfp.csv\", index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56737532",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset(df)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911c857d",
   "metadata": {},
   "source": [
    "Then we setup the `LANTERN` model, and load the pre-trained model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ba4983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lantern.model.basis import VariationalBasis\n",
    "from lantern.model.surface import Phenotype\n",
    "from lantern.model import Model\n",
    "\n",
    "import torch\n",
    "\n",
    "K=8\n",
    "model = Model(\n",
    "    VariationalBasis.fromDataset(ds, K=K),\n",
    "    Phenotype.fromDataset(ds, K=K)\n",
    ")\n",
    "\n",
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "        \"../manuscript/experiments/gfp-brightness/lantern/full/model.pt\",\n",
    "        \"cpu\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db04157a",
   "metadata": {},
   "source": [
    "## Plot the avGFP brightness surface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065e36c8",
   "metadata": {},
   "source": [
    "We first plot the non-linear surface across $z_1$ and $z_2$ by:\n",
    "1. Finding the range of values observed for $z_1$ and $z_2$ across the dataset.\n",
    "2. Building a dense mesh of points covering the range of values in these two dimensions.\n",
    "3. Predicting the surface at these points\n",
    "4. Plotting the surface contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287bd3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# find z1, z2\n",
    "z1, z2 = model.basis.order[:2]\n",
    "\n",
    "# get mutations and brightness for all observations\n",
    "X, y = ds[:len(ds)]\n",
    "\n",
    "# get the embedding for all data points\n",
    "with torch.no_grad():\n",
    "    Z = model.basis(X)\n",
    "\n",
    "# to filter outliers, only plot the points within [q/2, 1-q/2] quantile of each latent dimension\n",
    "q = 0.01\n",
    "\n",
    "# number of surface points\n",
    "N = 100\n",
    "\n",
    "# the meshgrid is used for surface plotting\n",
    "Z1, Z2 = np.meshgrid(\n",
    "    np.linspace(np.quantile(Z[:, z1], q/2), np.quantile(Z[:, z1], 1 - q/2), N),\n",
    "    np.linspace(np.quantile(Z[:, z2], q/2), np.quantile(Z[:, z2], 1 - q/2), N )\n",
    ")\n",
    "\n",
    "# predict the surface at each meshgrid point\n",
    "Zpred = torch.zeros(N**2, model.basis.K)\n",
    "Zpred[:, z1] = torch.from_numpy(Z1.ravel())\n",
    "Zpred[:, z2] = torch.from_numpy(Z2.ravel())\n",
    "\n",
    "# predict the surface\n",
    "with torch.no_grad():\n",
    "    fpred = model.surface(Zpred)\n",
    "    \n",
    "# scale to original brightness values and reshape for plotting\n",
    "f = fpred.mean * df[\"medianBrightness\"].std() + df[\"medianBrightness\"].mean()\n",
    "f = f.reshape(Z1.shape)\n",
    "\n",
    "# also scale the data for plotting\n",
    "y = y * df[\"medianBrightness\"].std() + df[\"medianBrightness\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071542a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3,2), dpi=300)\n",
    "\n",
    "im = plt.contourf(Z1, Z2, f, levels=8)\n",
    "plt.xlabel(\"$z_1$\")\n",
    "plt.ylabel(\"$z_2$\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826995ef",
   "metadata": {},
   "source": [
    "Next, we add the scatter of measured datapoints for comparison, coloring them by their measured value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6172d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3,2), dpi=300)\n",
    "\n",
    "im = plt.contour(Z1, Z2, f, levels=8)\n",
    "plt.scatter(Z[:, z1].numpy(), Z[:, z2].numpy(), c = y, alpha=0.8, s=0.3, rasterized=True)\n",
    "\n",
    "# re-apply the limits\n",
    "plt.xlim(np.quantile(Z[:, z1], q/2), np.quantile(Z[:, z1], 1 - q/2))\n",
    "plt.ylim(np.quantile(Z[:, z2], q/2), np.quantile(Z[:, z2], 1 - q/2))\n",
    "\n",
    "plt.xlabel(\"$z_1$\")\n",
    "plt.ylabel(\"$z_2$\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f29b64b",
   "metadata": {},
   "source": [
    "## Highlighting mutations in the surface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2179e672",
   "metadata": {},
   "source": [
    "To highlight specific mutations in the surface, we find the mutation effect vectors in the matrix $W$ and plot them over the surface contour. We re-calculate the contour predictions on the more narrow focused region around the origin. The mutations shown here are previously identified stabilizing substitutions for the blue fluorescent derivative of avGFP (BFP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6e8146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BFP stabilizing mutations\n",
    "subs = [\"SY143F\", \"SS63T\", \"SH229L\",'SY37N', 'SN103T', 'SY143F', 'SI169V', 'SN196S', 'SA204V']\n",
    "labels = [s[1:] for s in subs]\n",
    "ind = [ds.tokenizer.tokens.index(s) for s in subs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06de571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average mutation effects\n",
    "W = model.basis.W_mu.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b7d7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rebuid the surface in a focused region\n",
    "Z1, Z2 = np.meshgrid(\n",
    "    np.linspace(-1.7, 2.6, N),\n",
    "    np.linspace(-0.6, 0.3, N )\n",
    ")\n",
    "\n",
    "# predict the surface at each meshgrid point\n",
    "Zpred = torch.zeros(N**2, model.basis.K)\n",
    "Zpred[:, z1] = torch.from_numpy(Z1.ravel())\n",
    "Zpred[:, z2] = torch.from_numpy(Z2.ravel())\n",
    "\n",
    "# predict the surface\n",
    "with torch.no_grad():\n",
    "    fpred = model.surface(Zpred)\n",
    "    \n",
    "# scale to original brightness values and reshape for plotting\n",
    "f = fpred.mean * df[\"medianBrightness\"].std() + df[\"medianBrightness\"].mean()\n",
    "f = f.reshape(Z1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fecc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(3, 2), dpi=300)\n",
    "\n",
    "plt.contour(Z1, Z2, f, levels=8)\n",
    "\n",
    "for i in ind:\n",
    "    _z = W[i, [z1, z2]]\n",
    "    plt.arrow(\n",
    "        0,\n",
    "        0,\n",
    "        _z[0],\n",
    "        _z[1],\n",
    "        color=\"C{}\".format(ind.index(i)),\n",
    "        label=\"+{}\".format(labels[ind.index(i)]),\n",
    "        length_includes_head=True,\n",
    "        width=0.01,\n",
    "    )\n",
    "\n",
    "fig.legend(                    \n",
    "    ncol=1,                    \n",
    "    bbox_to_anchor=(1.01, 0.9),\n",
    "    loc=\"upper left\",          \n",
    "    borderaxespad=0.0,         \n",
    ")\n",
    "\n",
    "plt.xlabel(\"$z_1$\")\n",
    "plt.ylabel(\"$z_2$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb6ad7a",
   "metadata": {},
   "source": [
    "## Mutational effect distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a791446",
   "metadata": {},
   "source": [
    "To plot the distribution of effects learned by LANTERN in the two highest relevant dimension ($z_1$ and $z_2$), we compute the angle of each mutational effect vector and plot their histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6237e4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2, 2), dpi=300)\n",
    "ax = plt.subplot(111, polar=True)\n",
    "\n",
    "# \"y\" is the first argument to arctan2\n",
    "theta = np.arctan2(W[:, z2], W[:, z1])\n",
    "\n",
    "H, edges = np.histogram(theta, bins=80, density=True)\n",
    "\n",
    "ax = plt.subplot(111, polar=\"true\")\n",
    "\n",
    "# offset the bottom of the histogram\n",
    "bottom = H.max() * 0.5\n",
    "\n",
    "bars = ax.bar(\n",
    "    edges[1:],\n",
    "    H,\n",
    "    width=edges[1:] - edges[:-1],\n",
    "    bottom=bottom,\n",
    "    zorder=100,\n",
    ")\n",
    "ax.set_yticklabels([])\n",
    "\n",
    "for h, b in zip(H, bars):\n",
    "    b.set_edgecolor(\"k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8de8048",
   "metadata": {},
   "source": [
    "## Model dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c86ed34",
   "metadata": {},
   "source": [
    "To determine the dimensionality of the model, we find the highest $i$ such that $\\log_{10} \\sigma^2_k / \\sigma^2_{k+1} > 1$. In other words, the lowest variance dimension that has at least a ten-fold increase in variance over the previous. This heuristic was sufficient to determine the correct landscape dimension for simulated data (see manuscript for more details). We show how to plot the fold change of dimensions, highlighting those that are included with this procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a2902a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get basis dimension variances (inverse precision)\n",
    "qalpha = model.basis.qalpha(detach=True)\n",
    "sigmak = 1 / qalpha.mean[model.basis.order].numpy() # sort by the determined z1, z2, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d7acca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = (sigmak[:-1] / sigmak[1:])[::-1]\n",
    "thresh = 1\n",
    "\n",
    "# find the first dimension where at least a ten-fold change occurs\n",
    "select = (np.where(np.log10(fold) > thresh)[0]).min()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(3, 2), dpi=300)\n",
    "plt.plot(fold, marker=\"o\")\n",
    "plt.scatter(range(select, K-1), fold[select:], facecolors=\"none\", s=100, edgecolors=\"C0\")\n",
    "plt.xticks(range(K-1), [f\"z{K-k-1}\" for k in range(K-1)])\n",
    "plt.ylabel(\"fold-change\")\n",
    "plt.axhline(10**thresh, c=\"r\", ls=\"--\")\n",
    "\n",
    "plt.semilogy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3146aaae",
   "metadata": {},
   "source": [
    "We can also review the variance of each dimension directly. First looking at the total variance for each dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63b7951",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 2), dpi=300)\n",
    "plt.plot(np.arange(1, model.basis.K+1), sigmak, marker=\"o\")\n",
    "plt.semilogy()\n",
    "\n",
    "plt.xlabel(\"dimension\")\n",
    "plt.ylabel(\"$\\sigma^2_k$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2f482c",
   "metadata": {},
   "source": [
    "And also as a percentage of total variance for the mutational effect space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120b9a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 2), dpi=300)\n",
    "plt.plot(np.arange(1, model.basis.K+1), sigmak / sigmak.sum(), marker=\"o\")\n",
    "plt.semilogy()\n",
    "\n",
    "plt.xlabel(\"dimension\")\n",
    "plt.ylabel(\"% total variance\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
